<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Sun-E: Dataset and Benchmark for Event-Based Sun Sensing">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="sun sensing, event cameras, computer vision">
  <!-- TODO: List all authors -->
  <meta name="author" content="Sydney Dolan, Alessandro Golkar">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="Technical University of Munich">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Sun-E: Dataset and Benchmark for Event-Based Sun Sensing">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="PAPER_TITLE - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="Sydney Dolan">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="event cameras">
  <meta property="article:tag" content="sun sensing">



  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Sun-E: Dataset and Benchmark for Event-Based Sun Sensing">
  <meta name="citation_author" content="Dolan, Sydney">
  <meta name="citation_author" content="Golkar, Alessandro">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Sun-E: Dataset and Benchmark for Event-Based Sun Sensingh</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/SunSensorDiagram-2-1.png">
  <link rel="apple-touch-icon" href="static/images/SunSensorDiagram-2-1.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "Sydney Dolan",
        "affiliation": {
          "@type": "Organization",
          "name": "Technical University of Munich"
        }
      },
      {
        "@type": "Person",
        "name": "Alessandro Golkar",
        "affiliation": {
          "@type": "Organization",
          "name": "Technical University of Munich"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/SunSensorDiagram-2-1.png",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>



  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Sun-E: Dataset and Benchmark for Event-Based Sun Sensing</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://sydneyidolan.com" target="_blank">Sydney Dolan</a>,</span>
                <span class="author-block">
                  <a href="https://www.professoren.tum.de/en/golkar-alessandro" target="_blank">Alessandro Golkar</a></span>
                  <span class="author-block">
        
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <!-- TODO: Replace with your institution and conference/journal info -->
                    <span class="author-block">Technical University of Munich<br></span>
    
                  </div>

                  <div class="column has-text-centered">
                    <div class="link-block">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <a href="https://sydneyid.github.io/sun_e_proj/static/pdfs/Sun_E_Preprint.pdf" target="_blank"
                       class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- TODO: Add your supplementary material PDF or remove this section -->
                    <span class="link-block">
                      <a href="https://figshare.com/articles/dataset/Dataset_Information/30171373" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Event cameras are increasingly being explored for space applications due to their high dynamic range and increased spatiotemporal resolution. Existing datasets in this application have focused on capturing low-light, sub-pixel space objects and Earth observation scenarios. There remains a notable gap in datasets tailored to high-illumination conditions, particularly those involving direct solar imaging. This work introduces a dataset of solar event recordings captured with an event camera in a controlled sun-simulator environment. The dataset is specifically designed to support research in sun sensing and stray light analysis for spacecraft attitude estimation applications. It includes raw event data, annotated sun centroid locations, object motion profiles, and secondary optical aberration artifacts. In addition to the dataset, we present a systematic methodology for estimating the sun vector, intended to serve as a benchmark for evaluating sun sensing approaches in this application. All data and code are open source to facilitate further study.
         </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

  <!--/ Motivation. -->
<!--/ Motivation. -->
<!--/ Motivation. -->
<section class="section" id="Background">
  <div class="container is-max-desktop content">
    <h2 class="title">Motivation</h2>
    <p>
      Attitude sensors determine a spacecraft's orientation by sensing astronomical objects.
      Among attitude sensors, sun sensors are the most widely used due to their simplicity,
      low-power requirements, and the Sun's consistent visibility in space. Sun sensors estimate
      the direction and position of the sun relative to the spacecraft. Their working principle
      is shown in Figure 1.
    </p>

    <!-- Flex container -->
    <div style="display: flex; align-items: flex-start; gap: 2rem; margin: 2rem 0;">
      
      <!-- Left side: Image + caption -->
      <div style="flex: 0 0 auto; text-align: left;">
        <img src="./static/images/SunSensorDiagram-2-1.png"
             alt="Diagram of sun sensor operating principle"
             style="max-width: 300px; height: auto; display: block; margin-bottom: 0.5rem;" />
        <p style="margin: 0;">
          <b>Figure 1.</b> Ideal single-aperture sensor operating principle.<br />
          The two sun angles \( \alpha \) and \( \beta \) represent the relative sun angle.<br />
          Figure adapted from
          <a href="https://arxiv.org/abs/2507.21541" target="_blank" rel="noopener noreferrer">
            Herman (2025)
          </a>.
        </p>
      </div>

      <!-- Right side: Text -->
      <div style="flex: 1; text-align: left;">
        <p>
          The performance of centroiding methods for sun sensing has plateaued due to limitations
          in spatial resolution, optical blur, and susceptibility to noise. These constraints
          limit the achievable accuracy of sun sensors with conventional CMOS detectors.
          To address these challenges, we propose the use of event-based cameras for sun sensing.
          We introduce a dataset and associated benchmark, <b>Sun-E</b>, to facilitate further work in this field.
        </p>
      </div>
    </div>
  </div>
</section>


<!--/ Backgroundn. -->
<section class="section" id="Eventcamera_Description">
  <div class="container is-max-desktop content">
  <h2 class="title">What are event cameras?</h2>
  <p> Event-based vision is an alternative framework within visual sensing that pulls inspiration from the human visual system’s capability to detect and respond to motion changes in the environment. the vision system receives visual input asynchronously and transports this input to the visual cortex for processing. Cells in the retinal, composed of photoreceptors, bipolar cells, and ganglion cells, work together to detect changes in light intensity and motion. This biological system has inspired the development of event cameras, which operate on a similar principle.</p>
  <img src="./static/images/event_pixel_old_design.png"
    class="center-image"
    alt="Event pixel diagram. light hits the photoreceptor, which converts it to a voltage. voltage is carried to a change amplifier, which changes its intensity. Then the signal is carried to the comparatators, which convert input into events by comparing it against thresholds."
    style="max-width: 80%; height: auto;"/>  
  <p><b>Figure 2.</b> Event cameras mimic the structure of retinal cells by using pixels that independently convert light into voltage signals, responding to changes in brightness detected at each pixel.</p>

  <p>Events are read off a chip in the format <i>(t,x,y,p)</i> which includes the pixel's <i>xy</i> address on the pixel array, the polarity <i>(p)</i> of the change (ON or OFF) and a microsecond timestamp <i>(t)</i>. Together, the thousands of pixels in an event camera represent a dynamic view of the scene. The asynchronous update of each pixel occurs at an exceptionally high temporal resolution, enabling these cameras to adeptly capture fast-moving objects and dynamic scenes without the motion blur typically associated with frame cameras. Another key benefit of this class of camera is its ability to measure light intensity differences. Similar to the human eye, the event camera detects changes on a logarithmic scale, rather than with absolute values. This allows it to handle a wide range of lighting conditions effectively, avoiding common issues like overexposure or underexposure encountered with traditional frame camera systems. This adaptability is particularly valuable in environments with challenging lighting conditions like space. 
  </p>

  <div style="display: flex; justify-content: center; gap: 20px; align-items: flex-start;">
  <!-- First GIF -->
  <div>
    <img src="./static/images/normal_sc1.gif" alt="Description of first GIF" style="max-width: 80%; height: auto;" />
  </div>

  <!-- Second GIF -->
  <div>
    <img src="./static/images/event_sc1.gif" alt="Description of second GIF" style="max-width: 80%; height: auto;" />
  </div>
</div>

<!-- Figure caption -->
<p style="text-align: center; margin-top: 10px;">
  <strong>Figure 3.</strong> Side-by-side comparison of frame camera capture of a satellite detumbling (left), and an event camera capture (right).
</p>


</div>
</section>

<!--/ TO DO - Add a video or something to show normal representation vs event represntation. -->



<!--/ Backgroundn. -->
<section class="section" id="Motivation">
  <div class="container is-max-desktop content">
  <h2 class="title">What makes this dataset different??</h2>
  <p> Despite the growing interest in event-based vision for space applications, there exists a notable lack of publicly available datasets specifically tailored for sun sensing. This is a significant challenge to the development and evaluation of sun-sensing algorithms.</p>
    <p> </p>
    <img src="./static/images/V2EvsExperimental-1.png"
    class="center-image"
    alt="TODO: alt text"
    style="max-width: 80%; height: auto;"/>  
  <p><b>Figure 4.</b> Sample Comparison between simulated event-based solar imagery generated using event simulator v2e and experimentally captured event-based data. The initial scene was captured outdoors and not in the laboratory set-up used to produce the Sun-E dataset. The cluster of events near the top of the Event Camera recording corresponds to a ghost optical artifact.</p>
  <p> As illustrated by Figure 4, synthetic data diverges significantly from experimentally captured data. Synthetic event generators do not accurately model stray light artifacts within the scene. In this work, we address the broader gap in sun-sensing datasets by developing an experimental, high-fidelity dataset that captures realistic sunlight illumination and complex optical interactions. 
</p>

<p>
  The dataset consists of 9 scenes recorded with a fourth-generation event camera under varied sun angles, direction, and event sensor conditions. Each scene contains ground-truth metadata and auxiliary labels related to stray light analysis. Details about each scene are shown in the table below.
</p>
<table border="1" cellspacing="0" cellpadding="6">
  <caption>
    <strong> Table 1.</strong> Sequence descriptions. T: total time in seconds, MER: Mean event rate (kiloevents/second).
  </caption>
  <thead>
    <tr>
      <th>Alignment</th>
      <th>ID</th>
      <th>T</th>
      <th><em>f#</em></th>
      <th>Ghosts</th>
      <th>Flares</th>
      <th>Direction</th>
      <th>MER</th>
      <th>Biases</th>
    </tr>
  </thead>
  <tbody>
    <!-- Center -->
    <tr>
      <td rowspan="4">Center</td>
      <td>1</td>
      <td>60</td>
      <td>5</td>
      <td>✓</td>
      <td>✓</td>
      <td>Left</td>
      <td>832.3</td>
      <td>default</td>
    </tr>
    <tr>
      <td>2</td>
      <td>20</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Down</td>
      <td>649.6</td>
      <td>default</td>
    </tr>
    <tr>
      <td>3</td>
      <td>30</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Down</td>
      <td>654.0</td>
      <td>default</td>
    </tr>
    <tr>
      <td>4</td>
      <td>58</td>
      <td>8</td>
      <td>✓</td>
      <td>✓</td>
      <td>Right</td>
      <td>1224.7</td>
      <td>default</td>
    </tr>

    <!-- Upper -->
    <tr>
      <td rowspan="2">Upper</td>
      <td>5</td>
      <td>58</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Right</td>
      <td>750.4</td>
      <td>default</td>
    </tr>
    <tr>
      <td>6</td>
      <td>55</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Left</td>
      <td>699.1</td>
      <td>default</td>
    </tr>

    <!-- Lower -->
    <tr>
      <td rowspan="3">Lower</td>
      <td>7</td>
      <td>58</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Right</td>
      <td>784.7</td>
      <td>default</td>
    </tr>
    <tr>
      <td>8</td>
      <td>58</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Left</td>
      <td>782.1</td>
      <td>default</td>
    </tr>
    <tr>
      <td>9</td>
      <td>58</td>
      <td>5</td>
      <td>×</td>
      <td>✓</td>
      <td>Right</td>
      <td>802.2</td>
      <td>refractory</td>
    </tr>
  </tbody>
</table>

<p>
  In addition to the dataset, we provide a baseline methodology and evaluation protocol for event-based sun sensing. 
</p>
</div>
</section>

<!--/ Backgroundn. -->
<section class="section" id="Benchmark">
  <div class="container is-max-desktop content">
  <h2 class="title">How does our benchmark work?</h2>
  <p> Despite the growing interest in event-based vision for space applications, there exists a notable lack of publicly available datasets specifically tailored for sun sensing. This is a significant challenge to the development and evaluation of sun-sensing algorithms.</p>


  
  </div>
</section>



<!-- Image carousel -->
 <!--
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
       
        <img src="static/images/carousel1.jpg" alt="First research result visualization" loading="lazy"/>
      
        <h2 class="subtitle has-text-centered">
          First image description.
        </h2>
      </div>
      <div class="item">
       
        <img src="static/images/carousel2.jpg" alt="Second research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Second image description.
        </h2>
      </div>
      <div class="item">
       
        <img src="static/images/carousel3.jpg" alt="Third research result visualization" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
         Third image description.
       </h2>
     </div>
     <div class="item">
     
      <img src="static/images/carousel4.jpg" alt="Fourth research result visualization" loading="lazy"/>
      <h2 class="subtitle has-text-centered">
        Fourth image description.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
 -->




<!-- 
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
        
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
           
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
         
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
           
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
 -->






<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{YourPaperKey2024,
  title={Sun-E: Dataset and Benchmark for Event-Based Sun Sensing },
  author={Sydney Dolan and Alessandro Golkar},
  year={2025},
  url={https://sydneyid.github.io/sun_e_proj/}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
